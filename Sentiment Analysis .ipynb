{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1: Save the model and vectorizer\n",
    "# Add this to your existing script to save the trained model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create directory for models if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load your dataset\n",
    "# You can use your real data or the sample data as in your code\n",
    "reviews = [\n",
    "    \"This movie was excellent! The acting was superb.\",\n",
    "    \"Terrible film, I hated every minute of it.\",\n",
    "    \"Great movie with amazing special effects and plot.\",\n",
    "    \"Boring and predictable, waste of time.\",\n",
    "    \"I loved the characters and the storyline was intriguing.\"\n",
    "] * 20\n",
    "\n",
    "sentiments = [1, 0, 1, 0, 1] * 20  # 1 for positive, 0 for negative\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'text': reviews,\n",
    "    'sentiment': sentiments\n",
    "})\n",
    "\n",
    "# Text Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Feature Engineering: TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf, df['sentiment'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Training model with best hyperparameters (from your grid search)\n",
    "# Replace these with your actual best parameters\n",
    "best_params = {'n_estimators': 100, 'max_depth': None}  # Example values\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save the vectorizer and model\n",
    "with open('models/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "    \n",
    "with open('models/sentiment_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_rf, f)\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
